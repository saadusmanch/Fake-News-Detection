{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Semester 6\\FIT3162\\Fakeddit\n"
     ]
    }
   ],
   "source": [
    "cd \"d:/Semester 6/FIT3162/Fakeddit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentiment_vader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    \"\"\"\n",
    "    This class is used to build a pipeline for sentiment feature extraction using Vader\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.post_file = \"cleaned_df.csv\"\n",
    "        self.comment_file = \"cleaned_comments.csv\"\n",
    "        self.post_df = None\n",
    "        self.comment_df = None\n",
    "        self.comment_scores = {}\n",
    "    \n",
    "    def read_datasets(self):\n",
    "        self.post_df = pd.read_csv(self.post_file, index_col = 0)\n",
    "        self.comment_df = pd.read_csv(self.comment_file, index_col=0)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print(\"Number of Posts\", len(self.post_df))\n",
    "        print(\"Number of Comments\", len(self.comment_df))\n",
    "        print(\"Number of Fake Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 0]))\n",
    "        print(\"Number of True Posts\", len(self.post_df.loc[self.post_df['2_way_label'] == 1]))\n",
    "        \n",
    "    def get_sample_posts(self, sample_size):\n",
    "        self.post_df = self.post_df.sample(sample_size, random_state = 123).reset_index(drop=True)\n",
    "        \n",
    "    def filter_comments(self):\n",
    "        ids = self.post_df.id.unique()\n",
    "        self.comment_df = self.comment_df[self.comment_df['submission_id'].isin(ids)]\n",
    "        self.comment_df = self.comment_df.reset_index(drop=True)\n",
    "        \n",
    "    def build_comment_score(self):\n",
    "        #creating hashtables with post id as key\n",
    "        for ind in self.post_df.index:\n",
    "            # hastable for score of comments\n",
    "            self.comment_scores[self.post_df['id'][ind]] = [0, 0]\n",
    "        sentiment_vader.build_comment_dictionary(self.comment_df, self.comment_scores)\n",
    "        \n",
    "    def cmnt_sentiment_column(self):\n",
    "        \"\"\"\n",
    "        Add the comment sentiment Column to Post dataset\n",
    "        \"\"\"\n",
    "        temp = list(self.comment_scores.values())\n",
    "        score = [x[0]/x[1] if x[1] > 0 else x[1] for x in temp]\n",
    "        num_comments = [x[1] for x in temp]\n",
    "        \n",
    "        self.post_df[\"num_comments\"] = num_comments\n",
    "        self.post_df[\"comment_sentiment\"] = score\n",
    "            \n",
    "    def post_sentiment_column(self):\n",
    "        self.post_df['post_sentiment'] = self.post_df.apply(lambda x: sentiment_vader.post_sentiment(x['title']), axis=1)\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        print(\"Step 1: Reading Dataset\")\n",
    "        self.read_datasets()\n",
    "        print(\"Step 2: Filter Posts\")\n",
    "        self.get_sample_posts(10000)\n",
    "        print(\"Step 3: Filter Comments\")\n",
    "        self.filter_comments()\n",
    "        print(\"Step 4: Building Comment Score Dictionary\")\n",
    "        self.build_comment_score()\n",
    "        print(\"Step 6: Add Comment Score Column\")\n",
    "        self.cmnt_sentiment_column()\n",
    "        print(\"Step 7: Add Post Score Column\")\n",
    "        self.post_sentiment_column()\n",
    "        print(\"---DONE---\")\n",
    "        \n",
    "    def get_post_dataset(self):\n",
    "        return self.post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadu\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Filter Posts\n",
      "Step 3: Filter Comments\n",
      "Step 4: Building Comment Score Dictionary\n",
      "Step 6: Add Comment Score Column\n",
      "Step 7: Add Post Score Column\n",
      "---DONE---\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline object\n",
    "feature_extraction = FeatureExtraction()\n",
    "# Read the datasets\n",
    "feature_extraction.build_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Posts 10000\n",
      "Number of Comments 820028\n",
      "Number of Fake Posts 5194\n",
      "Number of True Posts 4806\n"
     ]
    }
   ],
   "source": [
    "# Print Statistics\n",
    "feature_extraction.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = feature_extraction.get_post_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>comment_sentiment</th>\n",
       "      <th>post_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i still cash in my brain needs to rest</td>\n",
       "      <td>2017-06-17 12:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>6hrnqx</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>Can I still cash in my brain needs to rest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how did the wheat say to its son photoshop</td>\n",
       "      <td>2019-07-27 18:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>cig6ey</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>How did the wheat say to its son Photoshop?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  can i still cash in my brain needs to rest  2017-06-17 12:58:22   \n",
       "1  how did the wheat say to its son photoshop  2019-07-27 18:58:22   \n",
       "\n",
       "                    domain      id  num_comments  score           subreddit  \\\n",
       "0  self.SubredditSimulator  6hrnqx            20     17  subredditsimulator   \n",
       "1  self.SubredditSimulator  cig6ey            20      3  subredditsimulator   \n",
       "\n",
       "                                         title  upvote_ratio  2_way_label  \\\n",
       "0   Can I still cash in my brain needs to rest           0.9            0   \n",
       "1  How did the wheat say to its son Photoshop?           1.0            0   \n",
       "\n",
       "   comment_sentiment  post_sentiment  \n",
       "0          -0.034000             0.0  \n",
       "1           0.196715             0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Domain Rank Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cheedcheed/top1m\n",
    "# https://github.com/mozilla/cipherscan/tree/master/top1m\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "class Alexa:\n",
    "    '''\n",
    "    this class provides access to the Alexa ranking of URLs\n",
    "    usage: create a new instance of this class (ranker = Alexa()) and use the get_rank method\n",
    "    '''\n",
    "    __domain_list = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # read the alexa ranking\n",
    "            f_csv = open('top-1m.csv/top-1m.csv')\n",
    "            csv_data = f_csv.read()\n",
    "            f_csv.close()\n",
    "            lines = csv_data.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    url = line.split(\",\")[1]\n",
    "                    url = re.sub('^www\\.', '', url)\n",
    "                    self.__domain_list.append(url)\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            raise\n",
    "        \n",
    "    def get_rank(self, url):\n",
    "        ''' getrank returns the alexa rank of the domain of the given URL, or -1 if it is over 1M'''\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.scheme == '':\n",
    "            return self.get_rank('http://'+url)\n",
    "        domain = parsed_url.netloc\n",
    "        domain = re.sub('^www\\.', '', domain)\n",
    "        if domain in self.__domain_list:\n",
    "            return self.__domain_list.index(domain)+1   \n",
    "        return 1000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexa = Alexa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexa.get_rank('www.cnn.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_domain_rank(df):\n",
    "    alexa = Alexa()\n",
    "    df['domain_rank'] = df.apply(lambda x: alexa.get_rank(x['domain']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Domain Rank Column\n"
     ]
    }
   ],
   "source": [
    "post_df = add_domain_rank(post_df)\n",
    "print(\"Added Domain Rank Column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Post DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>comment_sentiment</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>domain_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can i still cash in my brain needs to rest</td>\n",
       "      <td>2017-06-17 12:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>6hrnqx</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>Can I still cash in my brain needs to rest</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how did the wheat say to its son photoshop</td>\n",
       "      <td>2019-07-27 18:58:22</td>\n",
       "      <td>self.SubredditSimulator</td>\n",
       "      <td>cig6ey</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>subredditsimulator</td>\n",
       "      <td>How did the wheat say to its son Photoshop?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_title          created_utc  \\\n",
       "0  can i still cash in my brain needs to rest  2017-06-17 12:58:22   \n",
       "1  how did the wheat say to its son photoshop  2019-07-27 18:58:22   \n",
       "\n",
       "                    domain      id  num_comments  score           subreddit  \\\n",
       "0  self.SubredditSimulator  6hrnqx            20     17  subredditsimulator   \n",
       "1  self.SubredditSimulator  cig6ey            20      3  subredditsimulator   \n",
       "\n",
       "                                         title  upvote_ratio  2_way_label  \\\n",
       "0   Can I still cash in my brain needs to rest           0.9            0   \n",
       "1  How did the wheat say to its son Photoshop?           1.0            0   \n",
       "\n",
       "   comment_sentiment  post_sentiment  domain_rank  \n",
       "0          -0.034000             0.0      1000001  \n",
       "1           0.196715             0.0      1000001  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save Final Dataset\n",
    "post_df.to_csv('dataset.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Domain Rank\n",
    "# def get_alexa_ranking(url):\n",
    "#     \"\"\"\n",
    "#     Get Alexa ranking\n",
    "    \n",
    "#     \"\"\"\n",
    "#     from bs4 import BeautifulSoup\n",
    "#     import urllib.request\n",
    "# #     url='9news.com.au'\n",
    "#     rank_str =BeautifulSoup(urllib.request.urlopen(\"https://www.alexa.com/minisiteinfo/\" +url),'html.parser').table.a.get_text()\n",
    "#     try:    \n",
    "#         rank_int=int(rank_str.replace(',',''))\n",
    "#     except:\n",
    "#         rank_int = 1000001\n",
    "#     return rank_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from multiprocess import Pool, Manager\n",
    "# import sentiment\n",
    "# if __name__ == '__main__':\n",
    "#     print(\"Feature Extraction\")\n",
    "#     num_processors = 6\n",
    "#     pool = Pool(processes = num_processors)\n",
    "    \n",
    "#     manager = Manager()\n",
    "#     mgr_score = manager.dict()\n",
    "#     mgr_score.update(comment_scores)\n",
    "#     df_split = np.array_split(comment_df, num_processors)\n",
    "#     for data in df_split:\n",
    "#         pool.apply_async(sentiment.build_comment_dictionary, args = (data, mgr_score, ))\n",
    "#         print(\"done\")\n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
