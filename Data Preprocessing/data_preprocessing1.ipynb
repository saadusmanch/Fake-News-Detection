{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Semester 6\\FIT3162\\Fakeddit\n"
     ]
    }
   ],
   "source": [
    "cd \"d:/Semester 6/FIT3162/Fakeddit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(df, list_remove):\n",
    "    df = df.drop(list_remove, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_duplicated_posts(df):\n",
    "    \"\"\"\n",
    "    Duplication of posts are eliminated by checking the id of the post or comment.\n",
    "    Since the same id cannot exist twice, such posts are deleted\n",
    "    :param df: dataframe from which duplicated posts must be deleted\n",
    "    :return: dataframe which now contains unique posts or comments only\n",
    "    \"\"\"\n",
    "    # deleting duplicated posts\n",
    "    df = df.drop_duplicates(subset=['id'], keep=False)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_empty_posts(df, subset_list):\n",
    "    \"\"\"\n",
    "    This function deletes all empty posts in the dataset.\n",
    "    Empty posts are NaN\n",
    "    :param filename: name of the file from which the empty posts might be deleted\n",
    "    :param subset list of column names to remove empty values\n",
    "    :return: a dataframe holding the dataset after removing empty posts\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset = subset_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_removed_comments(df):\n",
    "    \"\"\"\n",
    "    This function deletes all removed or deleted comments in the dataset.\n",
    "    Empty posts can be denoted as [deleted] or [removed] or NaN\n",
    "    :param filename: name of the file from which the empty posts might be deleted\n",
    "    :param subset list of column names to remove empty values\n",
    "    :return: a dataframe holding the dataset after removing empty posts\n",
    "    \"\"\"\n",
    "    # Remove all rows which are deleted or removed\n",
    "    df = df.loc[(df['body'] != \"[deleted]\") & (df['body'] != \"[removed]\")]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_subreddits(df):\n",
    "    # Subreddits to Remove as they are based on images or photoshopped images.\n",
    "    sub_to_remove = [\"photoshopbattles\", \"pic\" , \"mildlyinteresting\", \"fakealbumcovers\", \"propagandaposters\",\n",
    "                 \"misleadingthumbnails\", \"pareidolia\", \"psbattle_artwork\", \"fakehistoryporn\"]\n",
    "    df = df[~df['subreddit'].isin(sub_to_remove)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change Date from UTC to Datetime\n",
    "def get_date(created):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "def change_date(df):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    df[\"created_utc\"] = df[\"created_utc\"].apply(get_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_posts(post_df, min_comments):\n",
    "    post_df = (post_df.loc[post_df['num_comments'] >= min_comments])\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_comments(df, ids):\n",
    "    df = df[df['submission_id'].isin(ids)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_post_dataset():\n",
    "    train_df = pd.read_csv(\"datasetv2/datasetv2.0/train.tsv\", sep='\\t')\n",
    "    test_df = pd.read_csv(\"datasetv2/datasetv2.0/test_public.tsv\", sep='\\t')\n",
    "    validate_df = pd.read_csv(\"datasetv2/datasetv2.0/validate.tsv\", sep='\\t')\n",
    "    post_df = pd.concat([train_df, test_df], axis=0)\n",
    "    post_df = pd.concat([post_df, validate_df], axis=0)\n",
    "    del train_df\n",
    "    del test_df\n",
    "    del validate_df\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_comment_dataset():\n",
    "    comment_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('comments', \"comment*.csv\"))))\n",
    "    comment_df = comment_df.reset_index(drop = True)\n",
    "    return comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_posts():\n",
    "    post_df = read_post_dataset()\n",
    "    remove_col = ['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1', 'hasImage',\n",
    "       'image_url', 'linked_submission_id', '3_way_label', '6_way_label', 'author']\n",
    "    post_df = remove_unwanted_columns(post_df, remove_col)\n",
    "    post_df = delete_empty_posts(post_df, subset_list=['title'])\n",
    "    post_df = delete_duplicated_posts(post_df)\n",
    "    post_df = remove_subreddits(post_df)\n",
    "    post_df = filter_posts(post_df, 20)\n",
    "    post_df = change_date(post_df)\n",
    "    post_df = post_df.reset_index(drop = True)\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_comments(ids):\n",
    "    comment_df = read_comment_dataset()\n",
    "    comment_df = delete_removed_comments(comment_df)\n",
    "    comment_df = delete_empty_posts(comment_df, ['submission_id', 'body'])\n",
    "    comment_df = remove_unwanted_columns(comment_df, ['Column1'])\n",
    "    comment_df = filter_comments(comment_df, ids)\n",
    "    comment_df = comment_df.reset_index(drop = True)\n",
    "    return comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Data Preprocessing\")\n",
    "    post_df = preprocess_posts()\n",
    "#     ids = post_df.id.unique()\n",
    "#     comment_df = preprocess_comments(ids)\n",
    "    post_df.to_csv(\"cleaned_df.csv\", encoding='utf-8-sig')\n",
    "#     comment_df.to_csv(\"cleaned_comments.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
